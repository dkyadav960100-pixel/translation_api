# Training Configuration for Motorola MT Assignment
# ================================================

# Data Sources
data:
  # WMT16 IT Domain - TRAINING DATA
  training:
    source: "WMT16"
    url: "https://www.statmt.org/wmt16/it-translation-task.html"
    files:
      - batch1_2: "http://ufallab.ms.mff.cuni.cz/~popel/batch1and2.zip"
      - indomain: "http://ufallab.ms.mff.cuni.cz/~popel/indomain_training.zip"
    language_pair: "en-nl"
    domain: "IT/Software"
    
  # Motorola Dataset - TEST DATA ONLY
  testing:
    source: "Dataset_Challenge_1.xlsx"
    samples: 84
    domain: "Mobile Device UI"
    columns:
      source: "English Source"
      target: "Reference Translation"

# Model Configuration
model:
  encoder_decoder:
    name: "Helsinki-NLP/opus-mt-en-nl"
    alternative: "facebook/mbart-large-50-many-to-many-mmt"
    max_length: 128
    beam_size: 5
    
  decoder_only:
    name: "meta-llama/Llama-2-7b-hf"
    alternative: "mistralai/Mistral-7B-v0.1"
    quantization: "4bit"
    lora:
      r: 16
      alpha: 32
      dropout: 0.05
      target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]

# Training Hyperparameters
training:
  encoder_decoder:
    batch_size: 16
    learning_rate: 5.0e-5
    warmup_steps: 500
    max_epochs: 10
    weight_decay: 0.01
    gradient_accumulation_steps: 2
    
  decoder_only:
    batch_size: 4
    learning_rate: 2.0e-4
    warmup_steps: 100
    max_epochs: 3
    gradient_accumulation_steps: 8

# Evaluation Metrics
evaluation:
  metrics:
    - bleu  # sacrebleu
    - chrf  # chrF++
    - ter   # Translation Edit Rate
    - comet # Neural metric
  checkpoint_metric: "bleu"
  higher_is_better: true

# Quality Estimation (Challenge 2)
quality_estimation:
  model: "wmt21-comet-qe-da"
  threshold: 0.6
  feedback_simulation: true

# Preprocessing
preprocessing:
  placeholder_patterns:
    - "{[0-9]+}"     # {1}, {2}
    - "{[a-z_]+}"    # {device}, {name}
    - "%[sd%]"       # %s, %d, %%
    - "\\$[a-z]+"    # $name, $value
  preserve_case: true
  normalize_unicode: true

# Hardware Settings
hardware:
  device: "auto"  # auto, cuda, cpu
  fp16: true
  gradient_checkpointing: true
  
# Logging
logging:
  level: "INFO"
  tensorboard: true
  wandb: false
  
# Paths
paths:
  data_dir: "data"
  output_dir: "outputs"
  checkpoint_dir: "outputs/checkpoints"
  logs_dir: "outputs/logs"
